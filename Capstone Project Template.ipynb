{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Data Analysis\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "In this project, We will explore Yelp dataset and find various data points that will help local businesses.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from -r requirement.txt (line 1)) (0.23.3)\n",
      "Requirement already satisfied: pyspark in /opt/spark-2.4.3-bin-hadoop2.7/python (from -r requirement.txt (line 2)) (2.4.3)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.6/site-packages (from -r requirement.txt (line 3)) (3.2.5)\n",
      "Requirement already satisfied: psycopg2 in /opt/conda/lib/python3.6/site-packages (from -r requirement.txt (line 4)) (2.7.4)\n",
      "Requirement already satisfied: configparser in /opt/conda/lib/python3.6/site-packages (from -r requirement.txt (line 5)) (3.8.1)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.6/site-packages (from -r requirement.txt (line 6)) (1.9.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/lib/python3.6/site-packages (from pandas->-r requirement.txt (line 1)) (2.6.1)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.6/site-packages (from pandas->-r requirement.txt (line 1)) (2017.3)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from pandas->-r requirement.txt (line 1)) (1.12.1)\n",
      "Requirement already satisfied: py4j==0.10.7 in /opt/conda/lib/python3.6/site-packages (from pyspark->-r requirement.txt (line 2)) (0.10.7)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from nltk->-r requirement.txt (line 3)) (1.11.0)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.7 in /opt/conda/lib/python3.6/site-packages (from boto3->-r requirement.txt (line 6)) (1.12.7)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3->-r requirement.txt (line 6)) (0.9.3)\n",
      "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /opt/conda/lib/python3.6/site-packages (from boto3->-r requirement.txt (line 6)) (0.1.13)\n",
      "Requirement already satisfied: docutils>=0.10 in /opt/conda/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.7->boto3->-r requirement.txt (line 6)) (0.14)\n",
      "Requirement already satisfied: urllib3<1.24,>=1.20 in /opt/conda/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.7->boto3->-r requirement.txt (line 6)) (1.22)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install -r requirement.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://86e2dfa97b79:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f17138404a8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "import psycopg2\n",
    "import uuid\n",
    "import re\n",
    "import os\n",
    "import configparser\n",
    "import boto3\n",
    "\n",
    "# Configuration\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config.get('AWS', 'AWS_ACCESS_KEY_ID')\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config.get('AWS', 'AWS_SECRET_ACCESS_KEY')\n",
    "\n",
    "# NLTK data setup\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Redshift connection setup\n",
    "conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(*config['CLUSTER'].values()))\n",
    "\n",
    "# Get the Spark session\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "-- From Yelp dataset, We will extract various data points related to an individual local business such as the trend of ratings, how many positive/negative reviews are, words their user highlighted and so on. In the end, We will build a dashboard to show those found data points to understand the current state of each local business.\n",
    "\n",
    "-- We will use Pyspark to read/transform data, Natural Language Toolkit to analyze reviews, Redshift to save analyzed data and Jupyter Notebook to build a dashboard.\n",
    "\n",
    "-- The data process pipeline in this notebook will only process a partial data set. This data process pipeline will be automated by Airflow Pipeline to process the whole data set.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_bucket = config.get(\"DATA_S3\", \"ETL_TEMP_S3_BUCKET\")\n",
    "data_folder = \"s3a://yura.udacity.dend.capstone.sample/\"\n",
    "temp_bucket = main_bucket + \"/temp/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Business data\n",
    "Contains business data including location data, attributes, and categories.\n",
    "\n",
    "```json\n",
    "{\n",
    "    // string, 22 character unique string business id\n",
    "    \"business_id\": \"tnhfDv5Il8EaGSXZGiuQGg\",\n",
    "    // string, the business's name\n",
    "    \"name\": \"Garaje\",\n",
    "    // string, the full address of the business\n",
    "    \"address\": \"475 3rd St\",\n",
    "    // string, the city\n",
    "    \"city\": \"San Francisco\",\n",
    "    // string, 2 character state code, if applicable\n",
    "    \"state\": \"CA\",\n",
    "    // string, the postal code\n",
    "    \"postal code\": \"94107\",\n",
    "    // float, latitude\n",
    "    \"latitude\": 37.7817529521,\n",
    "    // float, longitude\n",
    "    \"longitude\": -122.39612197,\n",
    "    // float, star rating, rounded to half-stars\n",
    "    \"stars\": 4.5,\n",
    "    // integer, number of reviews\n",
    "    \"review_count\": 1198,\n",
    "    // integer, 0 or 1 for closed or open, respectively\n",
    "    \"is_open\": 1,\n",
    "    // an array of strings of business categories\n",
    "    \"categories\": [\n",
    "        \"Mexican\",\n",
    "        \"Burgers\",\n",
    "        \"Gastropubs\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>attributes</th>\n",
       "      <th>business_id</th>\n",
       "      <th>categories</th>\n",
       "      <th>city</th>\n",
       "      <th>hours</th>\n",
       "      <th>is_open</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>review_count</th>\n",
       "      <th>stars</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2818 E Camino Acequia Drive</td>\n",
       "      <td>(None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>1SWheh84yJXfytovILXOAQ</td>\n",
       "      <td>Golf, Active Life</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>33.522143</td>\n",
       "      <td>-112.018481</td>\n",
       "      <td>Arizona Biltmore Golf Club</td>\n",
       "      <td>85016</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30 Eglinton Avenue W</td>\n",
       "      <td>(None, None, u'full_bar', {'romantic': False, ...</td>\n",
       "      <td>QXAEGFB4oINsVuTFxEYKFQ</td>\n",
       "      <td>Specialty Food, Restaurants, Dim Sum, Imported...</td>\n",
       "      <td>Mississauga</td>\n",
       "      <td>(9:0-1:0, 9:0-0:0, 9:0-1:0, 9:0-0:0, 9:0-0:0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>43.605499</td>\n",
       "      <td>-79.652289</td>\n",
       "      <td>Emerald Chinese Restaurant</td>\n",
       "      <td>L5R 3E7</td>\n",
       "      <td>128</td>\n",
       "      <td>2.5</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       address  \\\n",
       "0  2818 E Camino Acequia Drive   \n",
       "1         30 Eglinton Avenue W   \n",
       "\n",
       "                                          attributes             business_id  \\\n",
       "0  (None, None, None, None, None, None, None, Non...  1SWheh84yJXfytovILXOAQ   \n",
       "1  (None, None, u'full_bar', {'romantic': False, ...  QXAEGFB4oINsVuTFxEYKFQ   \n",
       "\n",
       "                                          categories         city  \\\n",
       "0                                  Golf, Active Life      Phoenix   \n",
       "1  Specialty Food, Restaurants, Dim Sum, Imported...  Mississauga   \n",
       "\n",
       "                                               hours  is_open   latitude  \\\n",
       "0                                               None        0  33.522143   \n",
       "1  (9:0-1:0, 9:0-0:0, 9:0-1:0, 9:0-0:0, 9:0-0:0, ...        1  43.605499   \n",
       "\n",
       "    longitude                        name postal_code  review_count  stars  \\\n",
       "0 -112.018481  Arizona Biltmore Golf Club       85016             5    3.0   \n",
       "1  -79.652289  Emerald Chinese Restaurant     L5R 3E7           128    2.5   \n",
       "\n",
       "  state  \n",
       "0    AZ  \n",
       "1    ON  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_df = spark.read.json(data_folder + 'business.json')\n",
    "business_df.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checkin data\n",
    "Checkins on a business.\n",
    "\n",
    "| business_id            | date                                                          |\n",
    "|------------------------|---------------------------------------------------------------|\n",
    "| --1UhMGODdWsrMastO9DZw | 2011-06-04 18:22:23, 2011-07-23 23:51:33, 2012-04-15 01:07:50 |\n",
    "| --6MefnULPED_I942VcFNA |  2014-12-29 19:25:50, 2015-01-17 01:49:14                     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>business_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-26 19:49:16, 2016-08-30 18:36:57, 2016...</td>\n",
       "      <td>--1UhMGODdWsrMastO9DZw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-06-04 18:22:23, 2011-07-23 23:51:33, 2012...</td>\n",
       "      <td>--6MefnULPED_I942VcFNA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                date             business_id\n",
       "0  2016-04-26 19:49:16, 2016-08-30 18:36:57, 2016...  --1UhMGODdWsrMastO9DZw\n",
       "1  2011-06-04 18:22:23, 2011-07-23 23:51:33, 2012...  --6MefnULPED_I942VcFNA"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df = spark.read.format('csv').option('header', 'true').load(data_folder + 'checkin.csv')\n",
    "checkin_df.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Review Data\n",
    "Contains full review text data including the user_id that wrote the review and the business_id the review is written for.\n",
    "\n",
    "```json\n",
    "{\n",
    "    // string, 22 character unique review id\n",
    "    \"review_id\": \"zdSx_SD6obEhz9VrW9uAWA\",\n",
    "    // string, 22 character unique user id, maps to the user in user.json\n",
    "    \"user_id\": \"Ha3iJu77CxlrFm-vQRs_8g\",\n",
    "    // string, 22 character business id, maps to business in business.json\n",
    "    \"business_id\": \"tnhfDv5Il8EaGSXZGiuQGg\",\n",
    "    // integer, star rating\n",
    "    \"stars\": 4,\n",
    "    // string, date formatted YYYY-MM-DD\n",
    "    \"date\": \"2016-03-09\",\n",
    "    // string, the review itself\n",
    "    \"text\": \"Great place to hang out after work: the prices are decent, and the ambience is fun. It's a bit loud, but very lively. The staff is friendly, and the food is good. They have a good selection of drinks.\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-05-07 04:34:36</td>\n",
       "      <td>1</td>\n",
       "      <td>Q1sbwvVQXV2734tPgoKj4Q</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "      <td>6</td>\n",
       "      <td>hG7b0MtEbXx5QzbzE6C_VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NZnhc2sEQy3RmzKTZnqtwQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-14 21:30:33</td>\n",
       "      <td>0</td>\n",
       "      <td>GJXCdrto3ASJOqKeVWPi6Q</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
       "      <td>0</td>\n",
       "      <td>yXQM5uF2jS6es16SJzNHfg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool                 date  funny  \\\n",
       "0  ujmEBvifdJM6h6RLv4wQIg     0  2013-05-07 04:34:36      1   \n",
       "1  NZnhc2sEQy3RmzKTZnqtwQ     0  2017-01-14 21:30:33      0   \n",
       "\n",
       "                review_id  stars  \\\n",
       "0  Q1sbwvVQXV2734tPgoKj4Q    1.0   \n",
       "1  GJXCdrto3ASJOqKeVWPi6Q    5.0   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  Total bill for this horrible service? Over $8G...       6   \n",
       "1  I *adore* Travis at the Hard Rock's new Kelly ...       0   \n",
       "\n",
       "                  user_id  \n",
       "0  hG7b0MtEbXx5QzbzE6C_VA  \n",
       "1  yXQM5uF2jS6es16SJzNHfg  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df = spark.read.json(data_folder + 'review.json')\n",
    "review_df.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tip data\n",
    "Tips written by a user on a business. Tips are shorter than reviews and tend to convey quick suggestions.\n",
    "\n",
    "```json\n",
    "{\n",
    "    // string, text of the tip\n",
    "    \"text\": \"Secret menu - fried chicken sando is da bombbbbbb Their zapatos are good too.\",\n",
    "    // string, when the tip was written, formatted like YYYY-MM-DD\n",
    "    \"date\": \"2013-09-20\",\n",
    "    // integer, how many compliments it has\n",
    "    \"compliment_count\": 172,\n",
    "    // string, 22 character business id, maps to business in business.json\n",
    "    \"business_id\": \"tnhfDv5Il8EaGSXZGiuQGg\",\n",
    "    // string, 22 character unique user id, maps to the user in user.json\n",
    "    \"user_id\": \"49JhAJh8vSQ-vM4Aourl0g\"\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>compliment_count</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>tip_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VaKXUpmWTTWDKbpJ3aQdMw</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-03-27 03:51:24</td>\n",
       "      <td>Great for watching games, ufc, and whatever el...</td>\n",
       "      <td>UPw5DWs_b-e2JRBS-t37Ag</td>\n",
       "      <td>9b9632e4-ab29-48fe-9af9-661b2637f54c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OPiPeoJiv92rENwbq76orA</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-05-25 06:00:56</td>\n",
       "      <td>Happy Hour 2-4 daily with 1/2 price drinks and...</td>\n",
       "      <td>Ocha4kZBHb4JK0lOWvE0sg</td>\n",
       "      <td>759056ea-2714-4d25-b1ea-07f8db2088c3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  compliment_count                 date  \\\n",
       "0  VaKXUpmWTTWDKbpJ3aQdMw                 0  2014-03-27 03:51:24   \n",
       "1  OPiPeoJiv92rENwbq76orA                 0  2013-05-25 06:00:56   \n",
       "\n",
       "                                                text                 user_id  \\\n",
       "0  Great for watching games, ufc, and whatever el...  UPw5DWs_b-e2JRBS-t37Ag   \n",
       "1  Happy Hour 2-4 daily with 1/2 price drinks and...  Ocha4kZBHb4JK0lOWvE0sg   \n",
       "\n",
       "                                 tip_id  \n",
       "0  9b9632e4-ab29-48fe-9af9-661b2637f54c  \n",
       "1  759056ea-2714-4d25-b1ea-07f8db2088c3  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uuid_udf = F.udf(lambda: str(uuid.uuid4()), StringType())\n",
    "\n",
    "tip_df = spark.read.json(data_folder + 'tip.json')\n",
    "tip_df = tip_df.withColumn(\"tip_id\", uuid_udf())\n",
    "tip_df.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### User data\n",
    "User data including the user's friend mapping and all the metadata associated with the user.\n",
    "\n",
    "```json\n",
    "{\n",
    "    // string, 22 character unique user id, maps to the user in user.json\n",
    "    \"user_id\": \"Ha3iJu77CxlrFm-vQRs_8g\",\n",
    "    // string, the user's first name\n",
    "    \"name\": \"Sebastien\",\n",
    "    // integer, the number of reviews they've written\n",
    "    \"review_count\": 56,\n",
    "    // string, when the user joined Yelp, formatted like YYYY-MM-DD\n",
    "    \"yelping_since\": \"2011-01-01\",\n",
    "    // array of strings, an array of the user's friend as user_ids\n",
    "    \"friends\": [\n",
    "        \"wqoXYLWmpkEH0YvTmHBsJQ\",\n",
    "        \"KUXLLiJGrjtSsapmxmpvTA\",\n",
    "        \"6e9rJKQC3n0RSKyHLViL-Q\"\n",
    "    ],\n",
    "    // array of integers, the years the user was elite\n",
    "    \"elite\": [\n",
    "        2012,\n",
    "        2013\n",
    "    ]\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_stars</th>\n",
       "      <th>compliment_cool</th>\n",
       "      <th>compliment_cute</th>\n",
       "      <th>compliment_funny</th>\n",
       "      <th>compliment_hot</th>\n",
       "      <th>compliment_list</th>\n",
       "      <th>compliment_more</th>\n",
       "      <th>compliment_note</th>\n",
       "      <th>compliment_photos</th>\n",
       "      <th>compliment_plain</th>\n",
       "      <th>...</th>\n",
       "      <th>cool</th>\n",
       "      <th>elite</th>\n",
       "      <th>fans</th>\n",
       "      <th>friends</th>\n",
       "      <th>funny</th>\n",
       "      <th>name</th>\n",
       "      <th>review_count</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "      <th>yelping_since</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>2015,2016,2017</td>\n",
       "      <td>5</td>\n",
       "      <td>c78V-rj8NQcQjOI8KP3UEA, alRMgPcngYSCJ5naFRBz5g...</td>\n",
       "      <td>17</td>\n",
       "      <td>Rashmi</td>\n",
       "      <td>95</td>\n",
       "      <td>84</td>\n",
       "      <td>l6BmjZMeQD3rDxWUbiAiow</td>\n",
       "      <td>2013-10-08 23:11:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>kEBTgDvFX754S68FllfCaA, aB2DynOxNOJK9st2ZeGTPg...</td>\n",
       "      <td>22</td>\n",
       "      <td>Jenna</td>\n",
       "      <td>33</td>\n",
       "      <td>48</td>\n",
       "      <td>4XChL029mKr5hydo79Ljxg</td>\n",
       "      <td>2013-02-21 22:29:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   average_stars  compliment_cool  compliment_cute  compliment_funny  \\\n",
       "0           4.03                1                0                 1   \n",
       "1           3.63                1                0                 1   \n",
       "\n",
       "   compliment_hot  compliment_list  compliment_more  compliment_note  \\\n",
       "0               2                0                0                1   \n",
       "1               1                0                0                0   \n",
       "\n",
       "   compliment_photos  compliment_plain         ...           cool  \\\n",
       "0                  0                 1         ...             25   \n",
       "1                  0                 0         ...             16   \n",
       "\n",
       "            elite  fans                                            friends  \\\n",
       "0  2015,2016,2017     5  c78V-rj8NQcQjOI8KP3UEA, alRMgPcngYSCJ5naFRBz5g...   \n",
       "1                     4  kEBTgDvFX754S68FllfCaA, aB2DynOxNOJK9st2ZeGTPg...   \n",
       "\n",
       "   funny    name  review_count useful                 user_id  \\\n",
       "0     17  Rashmi            95     84  l6BmjZMeQD3rDxWUbiAiow   \n",
       "1     22   Jenna            33     48  4XChL029mKr5hydo79Ljxg   \n",
       "\n",
       "         yelping_since  \n",
       "0  2013-10-08 23:11:33  \n",
       "1  2013-02-21 22:29:06  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df = spark.read.json(data_folder + 'user.json')\n",
    "user_df.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Business data\n",
    "We'd like to only analyze data for active businesses. Inactive(is_open = 0) business should be excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     100|\n",
      "+--------+\n",
      "\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      20|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_df.createOrReplaceTempView(\"business\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "select count(*) from business\n",
    "\"\"\").show()\n",
    "spark.sql(\"\"\"\n",
    "select count(*) from business where is_open = 0\n",
    "\"\"\").show()\n",
    "\n",
    "# Remove inactive businesses\n",
    "business_df = spark.sql(\"\"\"\n",
    "select * from business where is_open = 1\n",
    "\"\"\")\n",
    "business_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Review/Tip data\n",
    "We will tokenize and run the sentimental analysis for reviews and tips. If reviews or tips have en empty or null text, then they should be excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.createOrReplaceTempView(\"review\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "select count(*) from review where text is null or length(text) == 0\n",
    "\"\"\").show()\n",
    "\n",
    "# Remove review is null or emtpy review\n",
    "review_df = spark.sql(\"\"\"\n",
    "select * from review where text is not null and length(text) > 0\n",
    "\"\"\")\n",
    "review_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tip_df.createOrReplaceTempView(\"tip\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "select count(*) from tip where text is null or length(text) == 0\n",
    "\"\"\").show()\n",
    "\n",
    "# Remove tip is null or emtpy tip\n",
    "tip_df = spark.sql(\"\"\"\n",
    "select * from tip where text is not null and length(text) > 0\n",
    "\"\"\")\n",
    "tip_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "##### Fact tables\n",
    "\n",
    "1. review: Reviews in the review data and the result of the sentiment analysis\n",
    "    - <em>review_id, user_id, business_id, stars, date, text, sentiment</em>\n",
    "2. tip: Tips in the tip data and the result of the sentiment analysis\n",
    "    - <em>tip_id, user_id, date, business_id, text, sentiment</em>\n",
    "\n",
    "##### Demention tables\n",
    "\n",
    "1. business: Businesses in the business data\n",
    "    - <em>business_id, address, city, latitude, longitude, name, postal_code, state</em>\n",
    "2. business_category: Categories in the business data\n",
    "    - <em>business_id, category</em>\n",
    "3. review_text: Tokenized review texts\n",
    "    - <em>review_id, word</em>\n",
    "4. tip_text: Tokenized tip texts\n",
    "    - <em>tip_id, word</em>\n",
    "5. checkin: Checkin info in checkin data\n",
    "    - <em>business_id, date</em>\n",
    "6. user: User in the user data\n",
    "    - <em>user_id, name</em>\n",
    "7. user_elite: Elite users and years the user was elite\n",
    "    - <em>user_id, year</em>\n",
    "8. user_friend: Friends of elite users\n",
    "    - <em>user_id, friend_id</em>\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model\n",
    "\n",
    "1. Read the business data and load business and business categories information.\n",
    "    1. If a business have multiple business categories, they should be separate rows.\n",
    "2. Read the user data nad load user, elite user, user friends information.\n",
    "    1. If a user was the elite in multiple years, they should be separate rows.\n",
    "    2. We are only interested in Elite user's friends information. Only elite users' friend information should be saved to the user_friend.\n",
    "    3. If a user has multiple friends, they should be seperate rows.\n",
    "3. Read the checkin data and load checkin information.\n",
    "    1. The date field in the checkin data is a comma-separated list of timestamps for each checkin. Each individual checkin should be separate rows.\n",
    "4. Read the review data, and run the sentiment analysis and tokenization. Save them to each corresponding tables.\n",
    "    1. If a review has more the 'positive' element than the 'negative' from the result of sentiment analysis, the review should be considered a positive review, and vice versa.\n",
    "    2. The tokenization should be executed after the spelling check and the lemmatization, and known english stopwords should be excluded from tokens.\n",
    "5. Red the tip data and run the sentiment analysis and tokenization. Save them to each corresponding tables.\n",
    "    1. If a tip has more the 'positive' element than the 'negative' from the result of sentiment analysis, the review should be considered as a positive tip and vice versa.\n",
    "    2. The tokenization should be executed after the spelling check and the lemmatization, and known english stopwords should be excluded from tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: Create tables(This is only required one time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with conn.cursor() as cur:\n",
    "    cur.execute(open(\"create_tables.sql\", \"r\").read())\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_sql = \"\"\"\n",
    "COPY {}\n",
    "FROM 's3://{}/'\n",
    "IAM_ROLE '{}'\n",
    "FORMAT AS PARQUET\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.1.1 Load the business table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1SWheh84yJXfytovILXOAQ</td>\n",
       "      <td>2818 E Camino Acequia Drive</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>33.522143</td>\n",
       "      <td>-112.018481</td>\n",
       "      <td>Arizona Biltmore Golf Club</td>\n",
       "      <td>85016</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QXAEGFB4oINsVuTFxEYKFQ</td>\n",
       "      <td>30 Eglinton Avenue W</td>\n",
       "      <td>Mississauga</td>\n",
       "      <td>43.605499</td>\n",
       "      <td>-79.652289</td>\n",
       "      <td>Emerald Chinese Restaurant</td>\n",
       "      <td>L5R 3E7</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                      address         city  \\\n",
       "0  1SWheh84yJXfytovILXOAQ  2818 E Camino Acequia Drive      Phoenix   \n",
       "1  QXAEGFB4oINsVuTFxEYKFQ         30 Eglinton Avenue W  Mississauga   \n",
       "\n",
       "    latitude   longitude                        name postal_code state  \n",
       "0  33.522143 -112.018481  Arizona Biltmore Golf Club       85016    AZ  \n",
       "1  43.605499  -79.652289  Emerald Chinese Restaurant     L5R 3E7    ON  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_table_df = spark.sql(\"\"\"\n",
    "select\n",
    "    business_id,\n",
    "    address,\n",
    "    city,\n",
    "    latitude,\n",
    "    longitude,\n",
    "    name,\n",
    "    postal_code,\n",
    "    state\n",
    "from business\n",
    "\"\"\")\n",
    "business_table_df.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"business\"\n",
    "parquet_file_name = temp_bucket + table_name + \".parquet\"\n",
    "business_table_df.write.parquet(\"s3a://\" + parquet_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(copy_sql.format(\n",
    "            table_name,\n",
    "            parquet_file_name,\n",
    "            config.get(\"AWS\", \"AWS_IAM_ROLE\")))\n",
    "    conn.commit()\n",
    "except Exception as err:\n",
    "    print(\"Error: \", err)\n",
    "    conn.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.1.2 Load the business_category table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QXAEGFB4oINsVuTFxEYKFQ</td>\n",
       "      <td>Specialty Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QXAEGFB4oINsVuTFxEYKFQ</td>\n",
       "      <td>Restaurants</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id      categories\n",
       "0  QXAEGFB4oINsVuTFxEYKFQ  Specialty Food\n",
       "1  QXAEGFB4oINsVuTFxEYKFQ     Restaurants"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_category_table_df = business_df \\\n",
    "    .select(\"business_id\", \"categories\") \\\n",
    "    .withColumn(\"categories\", F.explode(F.split(\"categories\", \", \")))\n",
    "business_category_table_df.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"business_category\"\n",
    "parquet_file_name = temp_bucket + table_name + \".parquet\"\n",
    "business_category_table_df.write.parquet(\"s3a://\" + parquet_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(copy_sql.format(\n",
    "            table_name,\n",
    "            parquet_file_name,\n",
    "            config.get(\"AWS\", \"AWS_IAM_ROLE\")))\n",
    "    conn.commit()\n",
    "except Exception as err:\n",
    "    print(\"Error: \", err)\n",
    "    conn.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.2.1 Load user table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l6BmjZMeQD3rDxWUbiAiow</td>\n",
       "      <td>Rashmi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4XChL029mKr5hydo79Ljxg</td>\n",
       "      <td>Jenna</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id    name\n",
       "0  l6BmjZMeQD3rDxWUbiAiow  Rashmi\n",
       "1  4XChL029mKr5hydo79Ljxg   Jenna"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.createOrReplaceTempView(\"yelp_user\")\n",
    "user_table_df = spark.sql(\"\"\"\n",
    "select\n",
    "    user_id,\n",
    "    name\n",
    "from yelp_user\n",
    "\"\"\")\n",
    "user_table_df.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"yelp_user\"\n",
    "parquet_file_name = temp_bucket + table_name + \".parquet\"\n",
    "user_table_df.write.parquet(\"s3a://\" + parquet_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(copy_sql.format(\n",
    "            table_name,\n",
    "            parquet_file_name,\n",
    "            config.get(\"AWS\", \"AWS_IAM_ROLE\")))\n",
    "    conn.commit()\n",
    "except Exception as err:\n",
    "    print(\"Error: \", err)\n",
    "    conn.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.2.2 Load user_elite table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l6BmjZMeQD3rDxWUbiAiow</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l6BmjZMeQD3rDxWUbiAiow</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id  year\n",
       "0  l6BmjZMeQD3rDxWUbiAiow  2015\n",
       "1  l6BmjZMeQD3rDxWUbiAiow  2016"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_elite_table_df = spark.sql(\"\"\"\n",
    "select\n",
    "    user_id,\n",
    "    elite\n",
    "from yelp_user\n",
    "where elite is not null\n",
    "\"\"\")\n",
    "\n",
    "user_elite_table_df = user_elite_table_df \\\n",
    "    .withColumn(\"year\", F.explode(F.split(\"elite\", \",\"))) \\\n",
    "    .select(\"user_id\", \"year\")\n",
    "user_elite_table_df.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"yelp_user_elite\"\n",
    "parquet_file_name = temp_bucket + table_name + \".parquet\"\n",
    "user_elite_table_df.write.parquet(\"s3a://\" + parquet_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(copy_sql.format(\n",
    "            table_name,\n",
    "            parquet_file_name,\n",
    "            config.get(\"AWS\", \"AWS_IAM_ROLE\")))\n",
    "    conn.commit()\n",
    "except Exception as err:\n",
    "    print(\"Error: \", err)\n",
    "    conn.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.2.3 Load user_friend table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>friend_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l6BmjZMeQD3rDxWUbiAiow</td>\n",
       "      <td>c78V-rj8NQcQjOI8KP3UEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l6BmjZMeQD3rDxWUbiAiow</td>\n",
       "      <td>alRMgPcngYSCJ5naFRBz5g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id                friend_id\n",
       "0  l6BmjZMeQD3rDxWUbiAiow   c78V-rj8NQcQjOI8KP3UEA\n",
       "1  l6BmjZMeQD3rDxWUbiAiow   alRMgPcngYSCJ5naFRBz5g"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_friend_table_df = spark.sql(\"\"\"\n",
    "select\n",
    "    user_id,\n",
    "    friends\n",
    "from yelp_user\n",
    "where elite is not null and friends is not null\n",
    "\"\"\")\n",
    "\n",
    "user_friend_table_df = user_friend_table_df \\\n",
    "    .withColumn(\"friend_id\", F.explode(F.split(\"friends\", \",\"))) \\\n",
    "    .select(\"user_id\", \"friend_id\")\n",
    "user_friend_table_df.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"yelp_user_friend\"\n",
    "parquet_file_name = temp_bucket + table_name + \".parquet\"\n",
    "user_friend_table_df.write.parquet(\"s3a://\" + parquet_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(copy_sql.format(\n",
    "            table_name,\n",
    "            parquet_file_name,\n",
    "            config.get(\"AWS\", \"AWS_IAM_ROLE\")))\n",
    "    conn.commit()\n",
    "except Exception as err:\n",
    "    print(\"Error: \", err)\n",
    "    conn.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.3 Load checkin table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--1UhMGODdWsrMastO9DZw</td>\n",
       "      <td>2016-04-26 19:49:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--1UhMGODdWsrMastO9DZw</td>\n",
       "      <td>2016-08-30 18:36:57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                date\n",
       "0  --1UhMGODdWsrMastO9DZw 2016-04-26 19:49:16\n",
       "1  --1UhMGODdWsrMastO9DZw 2016-08-30 18:36:57"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_table_df = checkin_df \\\n",
    "    .withColumn(\"splited_date\", F.explode(F.split(\"date\", \", \"))) \\\n",
    "    .withColumn(\"casted_date\", F.to_timestamp(\"splited_date\", \"yyyy-MM-dd HH:mm:ss\")) \\\n",
    "    .select(\n",
    "        \"business_id\",\n",
    "        F.col(\"casted_date\").alias(\"date\")\n",
    "    )\n",
    "checkin_table_df.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"checkin\"\n",
    "parquet_file_name = temp_bucket + table_name + \".parquet\"\n",
    "checkin_table_df.write.parquet(\"s3a://\" + parquet_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(copy_sql.format(\n",
    "            table_name,\n",
    "            parquet_file_name,\n",
    "            config.get(\"AWS\", \"AWS_IAM_ROLE\")))\n",
    "    conn.commit()\n",
    "except Exception as err:\n",
    "    print(\"Error: \", err)\n",
    "    conn.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.4.1 Build the sentiment analyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment_analysis_score(sentence):\n",
    "    score = analyser.polarity_scores(sentence)\n",
    "    return score['compound']\n",
    "\n",
    "def get_sentiment_analysis_result(score):\n",
    "    if score >= 0.05:\n",
    "        return \"POSITIVE\"\n",
    "    elif score <= -0.05:\n",
    "        return \"NEGATIVE\"\n",
    "    else:\n",
    "        return \"NEUTRAL\"\n",
    "    \n",
    "get_sentiment_analysis_score_udf = F.udf(lambda x: get_sentiment_analysis_score(x), DoubleType())\n",
    "get_sentiment_analysis_result_udf = F.udf(lambda x: get_sentiment_analysis_result(x), StringType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.4.2 Build the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "tokenizer = RegexpTokenizer('\\w+|\\$[\\d\\.]+|\\S+')\n",
    "def tokenize(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    return tokens\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def is_not_stopword(word):\n",
    "    return not word in stop_words\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(word):\n",
    "    return lemmatizer.lemmatize(word)\n",
    "\n",
    "def is_valid_word(word):\n",
    "    return len(word) > 1 and not re.match(\"^([^a-z|0-9]|\\'[a-z|0-9])$\", word) and not word.isdecimal()\n",
    "    \n",
    "tokenize_udf = F.udf(lambda x: tokenize(x), ArrayType(StringType()))\n",
    "is_not_stopword_udf = F.udf(lambda x: is_not_stopword(x), BooleanType())\n",
    "lemmatize_udf = F.udf(lambda x: lemmatize(x), StringType())\n",
    "is_valid_word_udf = F.udf(lambda x: is_valid_word(x), BooleanType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.4.3 Load review table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_staging_df = spark.sql(\"\"\"\n",
    "select\n",
    "    review_id,\n",
    "    user_id,\n",
    "    business_id,\n",
    "    stars,\n",
    "    to_timestamp(date, 'yyyy-MM-dd HH:mm:ss') as date,\n",
    "    lower(text) as text\n",
    "from review\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1sbwvVQXV2734tPgoKj4Q</td>\n",
       "      <td>hG7b0MtEbXx5QzbzE6C_VA</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-05-07 04:34:36</td>\n",
       "      <td>total bill for this horrible service? over $8g...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GJXCdrto3ASJOqKeVWPi6Q</td>\n",
       "      <td>yXQM5uF2jS6es16SJzNHfg</td>\n",
       "      <td>NZnhc2sEQy3RmzKTZnqtwQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-01-14 21:30:33</td>\n",
       "      <td>i *adore* travis at the hard rock's new kelly ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  Q1sbwvVQXV2734tPgoKj4Q  hG7b0MtEbXx5QzbzE6C_VA  ujmEBvifdJM6h6RLv4wQIg   \n",
       "1  GJXCdrto3ASJOqKeVWPi6Q  yXQM5uF2jS6es16SJzNHfg  NZnhc2sEQy3RmzKTZnqtwQ   \n",
       "\n",
       "   stars                date  \\\n",
       "0    1.0 2013-05-07 04:34:36   \n",
       "1    5.0 2017-01-14 21:30:33   \n",
       "\n",
       "                                                text sentiment  \n",
       "0  total bill for this horrible service? over $8g...  NEGATIVE  \n",
       "1  i *adore* travis at the hard rock's new kelly ...  POSITIVE  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_table_df = review_staging_df \\\n",
    "    .withColumn(\"sa_score\", get_sentiment_analysis_score_udf(\"text\")) \\\n",
    "    .withColumn(\"sentiment\", get_sentiment_analysis_result_udf(\"sa_score\")) \\\n",
    "    .select(\n",
    "        \"review_id\",\n",
    "        \"user_id\",\n",
    "        \"business_id\",\n",
    "        \"stars\",\n",
    "        \"date\",\n",
    "        \"text\",\n",
    "        \"sentiment\")\n",
    "review_table_df.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"review\"\n",
    "parquet_file_name = temp_bucket + table_name + \".parquet\"\n",
    "review_table_df.write.parquet(\"s3a://\" + parquet_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(copy_sql.format(\n",
    "            table_name,\n",
    "            parquet_file_name,\n",
    "            config.get(\"AWS\", \"AWS_IAM_ROLE\")))\n",
    "    conn.commit()\n",
    "except Exception as err:\n",
    "    print(\"Error: \", err)\n",
    "    conn.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.4.4 Load review_text table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1sbwvVQXV2734tPgoKj4Q</td>\n",
       "      <td>total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q1sbwvVQXV2734tPgoKj4Q</td>\n",
       "      <td>bill</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id   word\n",
       "0  Q1sbwvVQXV2734tPgoKj4Q  total\n",
       "1  Q1sbwvVQXV2734tPgoKj4Q   bill"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_text_table_df = review_staging_df \\\n",
    "    .withColumn(\"word\", F.explode(tokenize_udf(\"text\"))) \\\n",
    "    .withColumn(\"word\", lemmatize_udf(\"word\")) \\\n",
    "    .filter(is_not_stopword_udf(\"word\")) \\\n",
    "    .filter(is_valid_word_udf(\"word\")) \\\n",
    "    .select(\n",
    "        \"review_id\",\n",
    "        \"word\")\n",
    "\n",
    "review_text_table_df.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"review_text\"\n",
    "parquet_file_name = temp_bucket + table_name + \".parquet\"\n",
    "review_text_table_df.write.parquet(\"s3a://\" + parquet_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(copy_sql.format(\n",
    "            table_name,\n",
    "            parquet_file_name,\n",
    "            config.get(\"AWS\", \"AWS_IAM_ROLE\")))\n",
    "    conn.commit()\n",
    "except Exception as err:\n",
    "    print(\"Error: \", err)\n",
    "    conn.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.5.1 Load tip table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tip_staging_df = spark.sql(\"\"\"\n",
    "select\n",
    "    tip_id,\n",
    "    user_id,\n",
    "    to_timestamp(date, 'yyyy-MM-dd HH:mm:ss') as date,\n",
    "    business_id,\n",
    "    lower(text) as text\n",
    "from tip\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tip_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>business_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9510aac3-8e37-4f8d-ae15-7bc411ecab5e</td>\n",
       "      <td>UPw5DWs_b-e2JRBS-t37Ag</td>\n",
       "      <td>2014-03-27 03:51:24</td>\n",
       "      <td>VaKXUpmWTTWDKbpJ3aQdMw</td>\n",
       "      <td>great for watching games, ufc, and whatever el...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b1ade63a-744b-4905-b80f-b743e4306d8f</td>\n",
       "      <td>Ocha4kZBHb4JK0lOWvE0sg</td>\n",
       "      <td>2013-05-25 06:00:56</td>\n",
       "      <td>OPiPeoJiv92rENwbq76orA</td>\n",
       "      <td>happy hour 2-4 daily with 1/2 price drinks and...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 tip_id                 user_id  \\\n",
       "0  9510aac3-8e37-4f8d-ae15-7bc411ecab5e  UPw5DWs_b-e2JRBS-t37Ag   \n",
       "1  b1ade63a-744b-4905-b80f-b743e4306d8f  Ocha4kZBHb4JK0lOWvE0sg   \n",
       "\n",
       "                 date             business_id  \\\n",
       "0 2014-03-27 03:51:24  VaKXUpmWTTWDKbpJ3aQdMw   \n",
       "1 2013-05-25 06:00:56  OPiPeoJiv92rENwbq76orA   \n",
       "\n",
       "                                                text sentiment  \n",
       "0  great for watching games, ufc, and whatever el...  POSITIVE  \n",
       "1  happy hour 2-4 daily with 1/2 price drinks and...  POSITIVE  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tip_table_df = tip_staging_df \\\n",
    "    .withColumn(\"sa_score\", get_sentiment_analysis_score_udf(\"text\")) \\\n",
    "    .withColumn(\"sentiment\", get_sentiment_analysis_result_udf(\"sa_score\")) \\\n",
    "    .select(\n",
    "        \"tip_id\",\n",
    "        \"user_id\",\n",
    "        \"date\",\n",
    "        \"business_id\",\n",
    "        \"text\",\n",
    "        \"sentiment\")\n",
    "tip_table_df.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"tip\"\n",
    "parquet_file_name = temp_bucket + table_name + \".parquet\"\n",
    "tip_table_df.write.parquet(\"s3a://\" + parquet_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(copy_sql.format(\n",
    "            table_name,\n",
    "            parquet_file_name,\n",
    "            config.get(\"AWS\", \"AWS_IAM_ROLE\")))\n",
    "    conn.commit()\n",
    "except Exception as err:\n",
    "    print(\"Error: \", err)\n",
    "    conn.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.5.2 Load tip_text table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tip_id</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37553bf8-5ea7-4251-8637-5a5c2d2a0968</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37553bf8-5ea7-4251-8637-5a5c2d2a0968</td>\n",
       "      <td>watching</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 tip_id      word\n",
       "0  37553bf8-5ea7-4251-8637-5a5c2d2a0968     great\n",
       "1  37553bf8-5ea7-4251-8637-5a5c2d2a0968  watching"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tip_text_table_df = tip_staging_df \\\n",
    "    .withColumn(\"word\", F.explode(tokenize_udf(\"text\"))) \\\n",
    "    .withColumn(\"word\", lemmatize_udf(\"word\")) \\\n",
    "    .filter(is_not_stopword_udf(\"word\")) \\\n",
    "    .filter(is_valid_word_udf(\"word\")) \\\n",
    "    .select(\n",
    "        \"tip_id\",\n",
    "        \"word\")\n",
    "\n",
    "tip_text_table_df.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"tip_text\"\n",
    "parquet_file_name = temp_bucket + table_name + \".parquet\"\n",
    "tip_text_table_df.write.parquet(\"s3a://\" + parquet_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(copy_sql.format(\n",
    "            table_name,\n",
    "            parquet_file_name,\n",
    "            config.get(\"AWS\", \"AWS_IAM_ROLE\")))\n",
    "    conn.commit()\n",
    "except Exception as err:\n",
    "    print(\"Error: \", err)\n",
    "    conn.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.6 Clean up the temp data in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(main_bucket)\n",
    "bucket.objects.filter(Prefix=\"temp\").delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.1.1 Script unit test : Non nullable field check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of null business_category.category: 0\n",
      "Count of null review_text.word: 0\n",
      "Count of null tip_text.word: 0\n",
      "Count of null yelp_user_elite.year: 0\n",
      "Count of null yelp_user_friend.friend_id: 0\n"
     ]
    }
   ],
   "source": [
    "non_nullable_fields = [\n",
    "    (\"business_category\", \"category\"),\n",
    "    (\"review_text\", \"word\"),\n",
    "    (\"tip_text\", \"word\"),\n",
    "    (\"yelp_user_elite\", \"year\"),\n",
    "    (\"yelp_user_friend\", \"friend_id\")\n",
    "]\n",
    "\n",
    "with conn.cursor() as cur:\n",
    "    for non_nullable_field in non_nullable_fields:\n",
    "        cur.execute(\"select count(*) from {} where {} is null\".format(non_nullable_field[0], non_nullable_field[1]))\n",
    "        print(\"Null count of {}.{}: {}\".format(non_nullable_field[0], non_nullable_field[1], str(cur.fetchone()[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.1.2 Script unit test : Sentiment analysis result check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid value count of review table: 0\n",
      "Invalid value count of tip table: 0\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis_tables = [\n",
    "    \"review\",\n",
    "    \"tip\"\n",
    "]\n",
    "\n",
    "with conn.cursor() as cur:\n",
    "    for table_name in sentiment_analysis_tables:\n",
    "        cur.execute(\"select count(*) from {} where sentiment not in ('POSITIVE', 'NEGATIVE', 'NEUTRAL')\".format(table_name))\n",
    "        print(\"Invalid value count of {} table: {}\".format(table_name, str(cur.fetchone()[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toggleable": false,
    "ulab": {
     "buttons": {
      "ulab-button-toggle-db4daf0f": {
       "style": "primary"
      }
     }
    }
   },
   "source": [
    "##### 4.2.2 Count check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of business table: 0\n",
      "Count of business_category table: 341\n",
      "Count of review table: 100\n",
      "Count of review_text table: 6960\n",
      "Count of tip table: 100\n",
      "Count of tip_text table: 706\n",
      "Count of checkin table: 13961\n",
      "Count of yelp_user table: 100\n",
      "Count of yelp_user_elite table: 263\n",
      "Count of yelp_user_friend table: 63777\n"
     ]
    }
   ],
   "source": [
    "table_names = [\n",
    "    \"business\",\n",
    "    \"business_category\",\n",
    "    \"review\",\n",
    "    \"review_text\",\n",
    "    \"tip\",\n",
    "    \"tip_text\",\n",
    "    \"checkin\",\n",
    "    \"yelp_user\",\n",
    "    \"yelp_user_elite\",\n",
    "    \"yelp_user_friend\"\n",
    "]\n",
    "\n",
    "with conn.cursor() as cur:\n",
    "    for table_name in table_names:\n",
    "        cur.execute(\"select count(*) from {}\".format(table_name))\n",
    "        print(\"Count of {} table: {}\".format(table_name, str(cur.fetchone()[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
